{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: This program uses artificial recurrent neural network called Long Short Term Memory (LSTM)\n",
    "#              to predict the closing stock price of a corporation using the past 60 day stock price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import math\n",
    "import pandas_datareader as web\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the stock quote \n",
    "df = web.DataReader('AAPL', data_source='yahoo', start='2012-01-01', end='2020-03-24')\n",
    "#Show the Data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the number of rows and columns in the data set\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the closing price history\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Close Price History')\n",
    "plt.plot(df['Close'])\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Data USE($)', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe with only the 'Close' column\n",
    "data=df.filter(['Close'])\n",
    "#Convert the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "#Get the number of rows to train the model on\n",
    "training_data_len = math.ceil( len(dataset) * .8 )\n",
    "\n",
    "training_data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data\n",
    "#Good practice to do? Why? Because its always advantageous to normalize the import data before presenting it to the network\n",
    "# and is very beneficial for the model\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "#Computes the MIN and Max values to be used for scaling then transforms the data based on these values\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As you can see these values are between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the training data set\n",
    "#Create the scaled training data set\n",
    "train_data = scaled_data[0:training_data_len , :]\n",
    "#Split the data into x_train & y_train data sets\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(train_data)):\n",
    "    x_train.append(train_data[i-60:i, 0]) #will contain 60 values indexed from 0 to 59\n",
    "    y_train.append(train_data[i, 0]) #will contain the 61st value, which will be postioned at 60\n",
    "    if i <= 61:\n",
    "        print(x_train)\n",
    "        print(y_train)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train data is all the values that are together\n",
    "# y_train is the single value 0.115444\n",
    "\n",
    "# We are training the data on the y_train value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the x_train and y_train to numpy arrays\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape the data\n",
    "#Why? We need it to be 3D because thats what the model expects and ours is currently 2D\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have made it into 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we finally can build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape = (x_train.shape[1], 1)))\n",
    "model.add(LSTM(50, return_sequences = False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error') \n",
    "\n",
    "#Optimizer is used to improve upon the loss function\n",
    "# The loss function is used to see how well the model did on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=1) #epoch is the number of iterations when a dataset is passed through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the testing data set\n",
    "#Create a new array containing scaled values from index 1543 to 2003\n",
    "\n",
    "test_data = scaled_data[training_data_len - 60: , :]\n",
    "#Create the data sets x_test and y_test\n",
    "x_test = []\n",
    "y_test = dataset [training_data_len:, :] #contains the 61st values non scaled\n",
    "\n",
    "for i in range(60, len(test_data)):\n",
    "    x_test.append(test_data[i-60:i, 0]) #contains the past 60 values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the data to a numpy array\n",
    "x_test = np.array(x_test) #converting it to a numpy array so that we can use it in the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape the data because it is 2D and we need 3D once again\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the models predicted price values\n",
    "predictions = model.predict(x_test)\n",
    "predictions = scaler.inverse_transform(predictions) #This is unscaling the values . \n",
    "#We want the same values as the y_test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the root mean sqaured error (RMSE)\n",
    "\n",
    "#RMSE is a good measure of how accurate the model predicts the response. Is the STD of the residuals\n",
    "\n",
    "# The lower the value of the RMSE shows a better fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A reading of 0 is a perfect match. We didnt get a value of 0, but ours is still decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the data\n",
    "train = data[:training_data_len]\n",
    "valid = data[training_data_len:]\n",
    "valid['Predictions'] = predictions\n",
    "#Visualize the data\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Model')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close','Predictions']])\n",
    "plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As you can see they are really close, so our model is good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the quote\n",
    "apple_quote = web.DataReader('AAPL', data_source='yahoo', start='2012-01-01', end='2020-03-24')\n",
    "\n",
    "#Create a new dataframe\n",
    "new_df = apple_quote.filter(['Close'])\n",
    "\n",
    "#Get the last 60 day closing price values and convert the DF to an array\n",
    "last_60_days = new_df[-60:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data to be values between 0 & 1\n",
    "last_60_days_scaled = scaler.transform(last_60_days)\n",
    "\n",
    "#Create an empty list\n",
    "X_test = []\n",
    "\n",
    "#Append the last 60 days to the x_list\n",
    "X_test.append(last_60_days_scaled)\n",
    "\n",
    "#Convert the X_test data set to a numpy array\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "#Reshape the data\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "#Get the predicted scaled price\n",
    "pred_price = model.predict(X_test)\n",
    "\n",
    "#undo the scaling\n",
    "pred_price = scaler.inverse_transform(pred_price)\n",
    "print(pred_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the quote\n",
    "apple_quote2 = web.DataReader('AAPL', data_source='yahoo', start='2020-03-25', end='2020-03-25')\n",
    "print(apple_quote2['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
